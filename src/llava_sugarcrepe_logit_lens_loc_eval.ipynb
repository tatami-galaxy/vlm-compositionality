{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from data_utils import(\n",
    "    load_sugarcrepe,\n",
    "    coco_cats,\n",
    "    coco_object_mask,\n",
    "    filter_sugarcrepe_distict_objects,\n",
    ")\n",
    "\n",
    "from llava_utils import(\n",
    "    llava_load_model, \n",
    "    llava_process_image, \n",
    "    llava_generate,\n",
    ")\n",
    "from lens_utils import(\n",
    "    llava_logit_lens,\n",
    "    get_mask_from_lens,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project directory\n",
    "project_dir = \"/root/vlm-compositionality\"\n",
    "\n",
    "# sugarcrepe\n",
    "dataset_dir = project_dir+'/data/raw/sugarcrepe'\n",
    "\n",
    "# coco images\n",
    "image_dir = project_dir+'/data/raw/coco/val2017'\n",
    "# coco annotations\n",
    "ann_dir = project_dir+'/data/raw/coco/annotations'\n",
    "ann_file = ann_dir+'/instances_val2017.json'\n",
    "\n",
    "# model constants\n",
    "model_name = \"llava-hf/llava-1.5-7b-hf\"\n",
    "topk = 50\n",
    "num_patches = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load dataset and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sugarcrepe\n",
    "sugarcrepe = load_sugarcrepe(dataset_dir)\n",
    "\n",
    "# load annotations\n",
    "coco=COCO(ann_file)\n",
    "\n",
    "# get coco image ids\n",
    "image_ids = coco.getImgIds()\n",
    "\n",
    "# filter images\n",
    "image_ids = filter_sugarcrepe_distict_objects(coco, image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model, processor\n",
    "model, processor = llava_load_model(model_name) #, flash_attention=False, torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eval loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image, get all object tokens for the image\n",
    "# for each object token generate logit lens mask and compare with coco mask\n",
    "for image_id in image_ids:\n",
    "\n",
    "    # image info\n",
    "    image_info = coco.loadImgs(image_id)[0]\n",
    "    image_file = image_info['file_name']\n",
    "    image_width = image_info['width']\n",
    "    image_height = image_info['height']\n",
    "\n",
    "    # object tokens\n",
    "    tokens = coco_cats(coco, image_id)\n",
    "\n",
    "    # get coco masks\n",
    "    token_to_mask = coco_object_mask(coco, image_id)\n",
    "\n",
    "    # load image\n",
    "    image = Image.open(image_dir+'/'+image_file).convert(\"RGB\")\n",
    "\n",
    "    # process image and prompt(default)\n",
    "    inputs = llava_process_image(image, processor, device=model.device)\n",
    "\n",
    "    # generate\n",
    "    outputs = llava_generate(inputs, model)\n",
    "\n",
    "    # get logit lens\n",
    "    # vocab_dim, num_layers, num_tokens\n",
    "    # TODO: what if token not in topk?\n",
    "    softmax_probs = llava_logit_lens(inputs, model, outputs, topk=topk)\n",
    "\n",
    "    # compare for each token\n",
    "\n",
    "    for token in tokens:\n",
    "        # get non zero mask from lens\n",
    "        ll_mask = get_mask_from_lens(\n",
    "            softmax_probs,\n",
    "            token,\n",
    "            processor,\n",
    "            num_patches,\n",
    "            image_width, image_height\n",
    "        )\n",
    "\n",
    "        # compare coco mask and logit lens mask\n",
    "        coco_mask = token_to_mask[token]\n",
    "\n",
    "        # f1 score to estimate overlap\n",
    "        f1 = f1_score(coco_mask.flatten(), ll_mask.flatten())\n",
    "        print(\"f1 score for {} : {}\".format(token, f1))\n",
    "        quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
