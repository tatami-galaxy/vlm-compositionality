{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils import llava_load_model, llava_process_image, llava_generate\n",
    "from lens_utils import llava_logit_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/drdo/vlm-compositionality/data\"\n",
    "dataset_folder = data_path+\"/raw/sugarcrepe\",\n",
    "image_folder = data_path+\"/raw/coco_val_2017\"\n",
    "model_name = \"llava-hf/llava-1.5-13b-hf\"\n",
    "image_file = image_folder+\"/000000008690.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load model, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "# TODO: random image\n",
    "image = Image.open(image_file)\n",
    "\n",
    "# load model, processor\n",
    "model, processor = llava_load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process image and prompt(default)\n",
    "inputs = llava_process_image(image, processor, device=model.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate\n",
    "outputs = llava_generate(inputs, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get logit lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: norm before unembedding\n",
    "# vocab_dim, num_layers, num_tokens\n",
    "softmax_probs = llava_logit_lens(inputs, model, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ = 'hair'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internal confidence heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_token_indices = processor.tokenizer.encode(class_)[1:]\n",
    "heatmap_data = softmax_probs[class_token_indices].max(axis=0).T\n",
    "\n",
    "# plot\n",
    "num_image_embeddings = softmax_probs.shape[2]\n",
    "im = plt.imshow(heatmap_data, aspect=30/num_image_embeddings, cmap='Blues', interpolation='nearest')\n",
    "plt.title(f\"'{class_}' probabilities\")\n",
    "plt.xlabel(\"LM Layer\")\n",
    "plt.ylabel(\"Image Embedding Index\")\n",
    "plt.tight_layout()\n",
    "plt.clim(0, 1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Max localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patches = 24\n",
    "img_width, img_height = image.size\n",
    "\n",
    "embedding_max = softmax_probs[class_token_indices].max(axis=0).max(axis=0)\n",
    "segmentation = embedding_max.reshape(num_patches, num_patches).astype(float)\n",
    "\n",
    "segmentation_resized = (np.array(Image.fromarray(segmentation).resize((img_width, img_height), Image.BILINEAR)))\n",
    "plt.imshow(image)\n",
    "plt.imshow(segmentation_resized, cmap='jet', interpolation='bilinear', alpha=.5)\n",
    "plt.axis('off')\n",
    "plt.title(f\"'{class_}' localization\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Localization by layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
