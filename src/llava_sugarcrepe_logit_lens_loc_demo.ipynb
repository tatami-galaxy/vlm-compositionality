{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils import llava_load_model, llava_process_image, llava_generate\n",
    "from lens_utils import llava_logit_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/drdo/vlm-compositionality/data\"\n",
    "dataset_folder = data_path+\"/raw/sugarcrepe\",\n",
    "image_folder = data_path+\"/raw/coco_val_2017\"\n",
    "model_name = \"llava-hf/llava-1.5-13b-hf\"\n",
    "image_file = image_folder+\"/000000008690.jpg\"\n",
    "\n",
    "num_patches = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load model, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "# TODO: RGB, COCO_val2014_000000562150.jpg\n",
    "image = Image.open(image_file) #.convert(\"RGB\")\n",
    "\n",
    "# load model, processor\n",
    "# TODO: float32\n",
    "model, processor = llava_load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process image and prompt(default)\n",
    "inputs = llava_process_image(image, processor, device=model.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate\n",
    "outputs = llava_generate(inputs, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get logit lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: norm before unembedding\n",
    "# vocab_dim, num_layers, num_tokens\n",
    "softmax_probs = llava_logit_lens(inputs, model, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ = 'hair'\n",
    "class_token_indices = processor.tokenizer.encode(class_)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internal confidence heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data = softmax_probs[class_token_indices].max(axis=0).T\n",
    "num_image_embeddings = softmax_probs.shape[2]\n",
    "im = plt.imshow(heatmap_data, aspect=30/num_image_embeddings, cmap='Blues', interpolation='nearest')\n",
    "plt.title(f\"'{class_}' probabilities\")\n",
    "plt.xlabel(\"LM Layer\")\n",
    "plt.ylabel(\"Image Embedding Index\")\n",
    "plt.tight_layout()\n",
    "plt.clim(0, 1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_localization(softmax_probs, class_token_indices, image, layer=None):\n",
    "\n",
    "    img_width, img_height = image.size\n",
    "\n",
    "    if layer is None:\n",
    "        softmax_probs = softmax_probs[class_token_indices].max(axis=0).max(axis=0)\n",
    "    else:\n",
    "        softmax_probs = softmax_probs[class_token_indices].max(axis=0)[layer]\n",
    "    segmentation = softmax_probs.reshape(num_patches, num_patches).astype(float)\n",
    "\n",
    "    segmentation_resized = (np.array(Image.fromarray(segmentation).resize((img_width, img_height), Image.BILINEAR)))\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(segmentation_resized, cmap='jet', interpolation='bilinear', alpha=.5)\n",
    "    plt.axis('off')\n",
    "    # TODO: layer in title\n",
    "    plt.title(f\"'{class_},' localization\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Max localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_localization(softmax_probs, class_token_indices, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Localization by layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_localization(softmax_probs, class_token_indices, image, 33)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
