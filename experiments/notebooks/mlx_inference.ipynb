{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ujan/opt/anaconda3/envs/native/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import mlx.core as mx\n",
    "from mlx_vlm import load, generate\n",
    "from mlx_vlm.prompt_utils import apply_chat_template\n",
    "from mlx_vlm.utils import load_config\n",
    "\n",
    "import json\n",
    "from transformers import AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 14 files:  29%|██▊       | 4/14 [00:03<00:07,  1.29it/s]Error while downloading from https://cdn-lfs-us-1.hf.co/repos/c0/70/c0703c964d73eab9f5b7a0709efae49a694794fb025e6562c9989e5515769296/b02a67d5d46d20cf51f10ed9961a17d8bb600c2aa34406afbd5cc4558555efc1?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00003-of-00004.safetensors%3B+filename%3D%22model-00003-of-00004.safetensors%22%3B&Expires=1733388049&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMzM4ODA0OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2MwLzcwL2MwNzAzYzk2NGQ3M2VhYjlmNWI3YTA3MDllZmFlNDlhNjk0Nzk0ZmIwMjVlNjU2MmM5OTg5ZTU1MTU3NjkyOTYvYjAyYTY3ZDVkNDZkMjBjZjUxZjEwZWQ5OTYxYTE3ZDhiYjYwMGMyYWEzNDQwNmFmYmQ1Y2M0NTU4NTU1ZWZjMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=Zq197FAocU273vtitJl0mDcLMCBCGt4O0qZf92bKGPZ6JHzot0etSp3CGovfgJampR0CMEtOMfHQtta212dioJcfHLkmO6lzrHK%7EviSPTF6qdj6sNSSHjq%7E-oARgdtGzxaf3eJfBOhkojopFuXw43sSITYvQomBwT4X1aVIeCp1PyjJN0D17c2rJZBXzq3ANmWS%7EL9HsKax1Xt5ZawvBoPPUUj%7EkiJYex0EQ%7EP6taeHNArLaEeCRHDcxDuEC8%7Eh1glFGqSjTvp11-CPe%7EhR12AmXQXKd4l-r7p-3HhAzGQKW0aPWGCeCcTAcJEtTKCGGtk9V%7EdQ4ZZH3WknKc1kMvw__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/c0/70/c0703c964d73eab9f5b7a0709efae49a694794fb025e6562c9989e5515769296/87ac69a67633349d1d25c2d9a3c1455c4cb32d67662fd39744fb69c0707de5b3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00004.safetensors%3B+filename%3D%22model-00001-of-00004.safetensors%22%3B&Expires=1733388049&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMzM4ODA0OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2MwLzcwL2MwNzAzYzk2NGQ3M2VhYjlmNWI3YTA3MDllZmFlNDlhNjk0Nzk0ZmIwMjVlNjU2MmM5OTg5ZTU1MTU3NjkyOTYvODdhYzY5YTY3NjMzMzQ5ZDFkMjVjMmQ5YTNjMTQ1NWM0Y2IzMmQ2NzY2MmZkMzk3NDRmYjY5YzA3MDdkZTViMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=jRuYbkNY9Ad5rSoJ8%7E16YxHp91NKOffxvj4TY4cL3%7EPgyZp9TNb5mDRZ99NDjWAlJF5ppAhR8tU7f7L1cpS7RsQUHtv80Z4jz1Ec3n6BbuK8X5h7s9Ld28n7WjVdewPicpKOI0y%7EmUohF5hpUbNAiBTJ3DPRVisoSIHzMYxR9pbVddDssJrFxcp9kEeoIeTmOXJ5baTPhZePTOqeqkt8qzJpyLpirr7g5EkCQQh97D-1nY8fIefGeeRuC-jjU%7EIHWHl0yWzWgnTzbnaPv73NHwR%7EfqlfVddoUqczS4mOhyisGhTLGtlk4M5ThmVDWlgrgzCKKVajVp5JdLRpASLwBQ__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/c0/70/c0703c964d73eab9f5b7a0709efae49a694794fb025e6562c9989e5515769296/2e5abb8d4e5fccd57ad1d49a7662ba3c80104bf17cd5e3b8fd81aa40c960fe95?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00002-of-00004.safetensors%3B+filename%3D%22model-00002-of-00004.safetensors%22%3B&Expires=1733388049&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMzM4ODA0OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2MwLzcwL2MwNzAzYzk2NGQ3M2VhYjlmNWI3YTA3MDllZmFlNDlhNjk0Nzk0ZmIwMjVlNjU2MmM5OTg5ZTU1MTU3NjkyOTYvMmU1YWJiOGQ0ZTVmY2NkNTdhZDFkNDlhNzY2MmJhM2M4MDEwNGJmMTdjZDVlM2I4ZmQ4MWFhNDBjOTYwZmU5NT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=b3-4iGOHeH5Kh4wkin4YEMXhtwFCcKd1w-6zVd6UGQlhzaaD11xQGpewtdF6De8LvMLM6D2QKSoWZOt35boHCUgHkxCaseEWZs3Z7ceFMjuWysorZ-YBMsDuG2A5ClcgVSU2uvOuD4l1JNhkXyQDu3t%7E8ex831KmnjHdvYSK5bjdDO%7ETMlXh-RbzW3O-XeGRaMuyZ-w6K9zdYV4EibaYcc7lPwqlxOfqWh1A8VhZijRWmyQIEiETxXJ5s4UBkVay62uX-Rh9TvwV7iId-chPiAjpzFZ7-fKxuETWJB0ZeC4I7p4gq9ZDto2NXSx69Sb-8fB0nMbMv8lUWhfzc-GPVw__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Fetching 14 files: 100%|██████████| 14/14 [1:12:49<00:00, 312.13s/it]  \n",
      "Fetching 14 files: 100%|██████████| 14/14 [00:00<00:00, 62468.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model_path = \"mlx-community/Qwen2-VL-7B-bf16\"\n",
    "model, mlx_processor = load(model_path)\n",
    "config = load_config(model_path)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": image,\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Describe the image.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Preparation for inference\n",
    "text = processor.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>Describe the image.<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a close-up of two cats sleeping on a pink blanket. One cat is lying down and the other is curled up in a ball. Both cats have stripes on their fur, and they are both looking towards the camera with their eyes closed. The cat lying down is wearing a green collar, and there are two remote controls on the blanket next to it. The cat curled up in a ball is wearing a pink collar, and there are also two remote controls on the blanket next to it\n"
     ]
    }
   ],
   "source": [
    "output = generate(model, mlx_processor, image, text, verbose=False)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [\n",
    "    \"http://images.cocodataset.org/val2017/000000039769.jpg\",\n",
    "    \"http://images.cocodataset.org/val2017/000000082807.jpg\"\n",
    "]\n",
    "prompt = \"Compare these two images.\"\n",
    "\n",
    "formatted_prompt = apply_chat_template(\n",
    "    processor, config, prompt, num_images=len(images)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nCompare these two images.<|vision_start|><|image_pad|><|vision_end|><|vision_start|><|image_pad|><|vision_end|><|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a scene with three animals: two cats and one dog. Here's a detailed description:\n",
      "\n",
      "1. **Cat on the left**: This cat is lying down and appears to be resting or sleeping. It has a black and white striped pattern, and it's lying on its back with its paws stretched out in front of it.\n",
      "\n",
      "2. **Dog in the middle**: This dog is also lying down and appears to be resting or sleeping as well. It has a brown coat with black\n"
     ]
    }
   ],
   "source": [
    "output = generate(model, mlx_processor, images, formatted_prompt, verbose=False)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/users/ujan/vlm-compositionality/data/raw/sugarcrepe/'\n",
    "\n",
    "# add attribute\n",
    "with open(folder_path+'add_att.json') as f:\n",
    "    add_attribute = json.load(f)\n",
    "\n",
    "# add object\n",
    "with open(folder_path+'add_obj.json') as f:\n",
    "    add_object = json.load(f)\n",
    "\n",
    "# replace attribute\n",
    "with open(folder_path+'replace_att.json') as f:\n",
    "    replace_attribute = json.load(f)\n",
    "\n",
    "# replace object\n",
    "with open(folder_path+'replace_obj.json') as f:\n",
    "    replace_object = json.load(f)\n",
    "\n",
    "# replace relation\n",
    "with open(folder_path+'replace_rel.json') as f:\n",
    "    replace_relation = json.load(f)\n",
    "\n",
    "# swap attribute\n",
    "with open(folder_path+'swap_att.json') as f:\n",
    "    swap_attribute = json.load(f)\n",
    "\n",
    "# swap object\n",
    "with open(folder_path+'swap_obj.json') as f:\n",
    "    swap_object = json.load(f)\n",
    "\n",
    "# collate together\n",
    "dataset = {\n",
    "    'add_attribute': add_attribute, 'add_object': add_object, 'replace_attribute': replace_attribute,\n",
    "    'replace_object': replace_object, 'replace_relation': replace_relation,\n",
    "    'swap_attribute': swap_attribute, 'swap_object': swap_object,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': '000000021503.jpg',\n",
       " 'caption': 'Crackers coated with spread, sitting on a plate, ready to eat.',\n",
       " 'negative_caption': 'Spread coated with crackers, sitting on a plate, ready to eat.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_folder = '/users/ujan/vlm-compositionality/data/raw/coco_val_2017/'\n",
    "\n",
    "id = '67'\n",
    "img_file = swap_object[id]['filename']\n",
    "caption = swap_object[id]['caption']\n",
    "negative_caption = swap_object[id]['negative_caption']\n",
    "swap_object[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>Choose and return the correct caption for the image from the following 2 captions. Generate no other text. Caption 1: Girls wash a motorcycle while men look on. Caption 2: Men wash a motorcycle while girls look on.'}<|im_end|>\\n<|im_start|>assistant\\nCaption 1<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>Choose and return the correct caption for the image from the following 2 captions. Generate no other text. Caption 1: Crackers coated with spread, sitting on a plate, ready to eat. Caption 2: Spread coated with crackers, sitting on a plate, ready to eat.<|im_end|>\\n<|im_start|>assistant\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": img_folder+'000000177934.jpg', },\n",
    "            {\"type\": \"text\", \"text\": \"Choose and return the correct caption for the image from the following 2 captions. Generate no other text. Caption 1: Girls wash a motorcycle while men look on. Caption 2: Men wash a motorcycle while girls look on.'}\"},\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Caption 1\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": img_folder+img_file, },\n",
    "            {\"type\": \"text\", \"text\": (\"Choose and return the correct caption for the image from the following 2 captions. Generate no other text. Caption 1: {} Caption 2: {}\").format(caption, negative_caption)},\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Preparation for inference\n",
    "text = processor.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [\n",
    "    img_folder+'000000177934.jpg',\n",
    "    img_folder+img_file\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generate(model, mlx_processor, images, text, verbose=False)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "native",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
